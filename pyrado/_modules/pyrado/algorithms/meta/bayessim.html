

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>pyrado.algorithms.meta.bayessim &mdash; Pyrado 0.5 documentation</title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/graphviz.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="icon icon-home"> Pyrado
          

          
          </a>

          
            
            
              <div class="version">
                0.5
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Examples:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../examples/1_basic_experiment.html">How to run an experiment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../examples/2_wrapping_environments.html">How to wrap an environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../examples/3_algorithm_skeleton.html">How to create an algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../examples/4_creating_rcspysim_environments.html">How to create an RcsPySim environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../examples/panda3d_basic_experiment.html"><strong>How to create a visualization</strong></a></li>
</ul>
<p class="caption"><span class="caption-text">Algorithms:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../algorithms.html">algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../algorithms.episodic.html">episodic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../algorithms.step_based.html">step_based</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../algorithms.meta.html">meta</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../exploration.html">exploration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../sampling.html">sampling</a></li>
</ul>
<p class="caption"><span class="caption-text">Environments:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../environments.html">environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../environments.pysim.html">pysim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../environments.mujoco.html">mujoco</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../environments.rcspysim.html">rcspysim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../environments.quanser.html">quanser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../environments.barrett_wam.html">barrett_wam</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../environment_wrappers.html">environment_wrappers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../domain_randomization.html">domain_randomization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../spaces.html">spaces</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tasks.html">tasks</a></li>
</ul>
<p class="caption"><span class="caption-text">Policies:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../policies.html">policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../policies.feed_forward.html">feed_forward</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../policies.recurrent.html">recurrent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../policies.special.html">special</a></li>
</ul>
<p class="caption"><span class="caption-text">Utilities:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../logger.html">logger</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../plotting.html">plotting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../utils.html">utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tests.html">tests</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">Pyrado</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
        
          <li><a href="../../../pyrado.html">pyrado</a> &raquo;</li>
        
      <li>pyrado.algorithms.meta.bayessim</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for pyrado.algorithms.meta.bayessim</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) 2020, Fabio Muratore, Honda Research Institute Europe GmbH, and</span>
<span class="c1"># Technical University of Darmstadt.</span>
<span class="c1"># All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># Redistribution and use in source and binary forms, with or without</span>
<span class="c1"># modification, are permitted provided that the following conditions are met:</span>
<span class="c1"># 1. Redistributions of source code must retain the above copyright</span>
<span class="c1">#    notice, this list of conditions and the following disclaimer.</span>
<span class="c1"># 2. Redistributions in binary form must reproduce the above copyright</span>
<span class="c1">#    notice, this list of conditions and the following disclaimer in the</span>
<span class="c1">#    documentation and/or other materials provided with the distribution.</span>
<span class="c1"># 3. Neither the name of Fabio Muratore, Honda Research Institute Europe GmbH,</span>
<span class="c1">#    or Technical University of Darmstadt, nor the names of its contributors may</span>
<span class="c1">#    be used to endorse or promote products derived from this software without</span>
<span class="c1">#    specific prior written permission.</span>
<span class="c1">#</span>
<span class="c1"># THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot; AND</span>
<span class="c1"># ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED</span>
<span class="c1"># WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE</span>
<span class="c1"># DISCLAIMED. IN NO EVENT SHALL FABIO MURATORE, HONDA RESEARCH INSTITUTE EUROPE GMBH,</span>
<span class="c1"># OR TECHNICAL UNIVERSITY OF DARMSTADT BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,</span>
<span class="c1"># SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,</span>
<span class="c1"># PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;</span>
<span class="c1"># OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER</span>
<span class="c1"># IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)</span>
<span class="c1"># ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE</span>
<span class="c1"># POSSIBILITY OF SUCH DAMAGE.</span>

<span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">to</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span> <span class="nn">torch.distributions</span> <span class="kn">import</span> <span class="n">Distribution</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Mapping</span>

<span class="kn">import</span> <span class="nn">pyrado</span>
<span class="kn">from</span> <span class="nn">pyrado.algorithms.base</span> <span class="kn">import</span> <span class="n">Algorithm</span>
<span class="kn">from</span> <span class="nn">pyrado.algorithms.inference.snpea</span> <span class="kn">import</span> <span class="n">SNPEA</span>
<span class="kn">from</span> <span class="nn">pyrado.algorithms.meta.sbi_base</span> <span class="kn">import</span> <span class="n">SBIBase</span>
<span class="kn">from</span> <span class="nn">pyrado.algorithms.utils</span> <span class="kn">import</span> <span class="n">until_thold_exceeded</span>
<span class="kn">from</span> <span class="nn">pyrado.environment_wrappers.domain_randomization</span> <span class="kn">import</span> <span class="n">DomainRandWrapper</span><span class="p">,</span> <span class="n">DomainRandWrapperBuffer</span>
<span class="kn">from</span> <span class="nn">pyrado.environments.base</span> <span class="kn">import</span> <span class="n">Env</span>
<span class="kn">from</span> <span class="nn">pyrado.environments.sim_base</span> <span class="kn">import</span> <span class="n">SimEnv</span>
<span class="kn">from</span> <span class="nn">pyrado.logger.step</span> <span class="kn">import</span> <span class="n">StepLogger</span>
<span class="kn">from</span> <span class="nn">pyrado.policies.base</span> <span class="kn">import</span> <span class="n">Policy</span>
<span class="kn">from</span> <span class="nn">pyrado.policies.special.mdn</span> <span class="kn">import</span> <span class="n">MDNPolicy</span>
<span class="kn">from</span> <span class="nn">pyrado.sampling.sbi_embeddings</span> <span class="kn">import</span> <span class="n">BayesSimEmbedding</span>
<span class="kn">from</span> <span class="nn">pyrado.sampling.sbi_rollout_sampler</span> <span class="kn">import</span> <span class="n">SimRolloutSamplerForSBI</span>
<span class="kn">from</span> <span class="nn">pyrado.spaces.box</span> <span class="kn">import</span> <span class="n">InfBoxSpace</span>
<span class="kn">from</span> <span class="nn">pyrado.spaces.discrete</span> <span class="kn">import</span> <span class="n">DiscreteSpace</span>
<span class="kn">from</span> <span class="nn">pyrado.utils.data_types</span> <span class="kn">import</span> <span class="n">merge_dicts</span><span class="p">,</span> <span class="n">EnvSpec</span>


<div class="viewcode-block" id="BayesSim"><a class="viewcode-back" href="../../../../algorithms.meta.html#pyrado.algorithms.meta.bayessim.BayesSim">[docs]</a><span class="k">class</span> <span class="nc">BayesSim</span><span class="p">(</span><span class="n">Algorithm</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    BayesSim [1] using Sequential Neural Posterior Estimation (SNPE-A) [2]</span>

<span class="sd">    .. seealso::</span>
<span class="sd">        [1] F. Ramos, R.C. Possas, D. Fox, &quot;BayesSim: adaptive domain randomization via probabilistic inference for</span>
<span class="sd">            robotics simulators&quot;, RSS, 2019</span>
<span class="sd">        [2] G. Papamakarios, I. Murray. &quot;Fast epsilon-free inference of simulation models with Bayesian conditional</span>
<span class="sd">            density estimation.&quot;, NIPS, 2016</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;bayessim&quot;</span>
    <span class="n">iteration_key</span> <span class="o">=</span> <span class="s2">&quot;bayessim_iteration&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">save_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">env_sim</span><span class="p">:</span> <span class="n">SimEnv</span><span class="p">,</span>
        <span class="n">env_real</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Env</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span>
        <span class="n">policy</span><span class="p">:</span> <span class="n">Policy</span><span class="p">,</span>
        <span class="n">dp_mapping</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span>
        <span class="n">prior</span><span class="p">:</span> <span class="n">Distribution</span><span class="p">,</span>
        <span class="n">embedding</span><span class="p">:</span> <span class="n">BayesSimEmbedding</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">num_real_rollouts</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">num_sim_per_round</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">num_segments</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">len_segments</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_sbi_rounds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">num_eval_samples</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posterior_hparam</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">subrtn_sbi_training_hparam</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">subrtn_sbi_snapshot_mode</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;latest&quot;</span><span class="p">,</span>
        <span class="n">subrtn_policy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Algorithm</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">subrtn_policy_snapshot_mode</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;latest&quot;</span><span class="p">,</span>
        <span class="n">thold_succ_subrtn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">pyrado</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">logger</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">StepLogger</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Constructor</span>

<span class="sd">        .. note::</span>
<span class="sd">            The `subrtn_sbi` ist not from the sbi package, it is called this way because it also does sbi.</span>

<span class="sd">        :param save_dir: directory to save the snapshots i.e. the results in</span>
<span class="sd">        :param env_sim: randomized simulation environment a.k.a. source domain</span>
<span class="sd">        :param env_real: real-world environment a.k.a. target domain, this can be a `RealEnv` (sim-to-real setting), a</span>
<span class="sd">                         `SimEnv` (sim-to-sim setting), or a directory to load a pre-recorded set of rollouts from</span>
<span class="sd">        :param policy: policy used for sampling the rollout, if subrtn_policy is not `None` this policy is not oly used</span>
<span class="sd">                       for generating the target domain rollouts, but also optimized in simulation</span>
<span class="sd">        :param dp_mapping: mapping from subsequent integers (starting at 0) to domain parameter names (e.g. mass)</span>
<span class="sd">        :param prior: distribution used by sbi as a prior</span>
<span class="sd">        :param embedding: embedding used for pre-processing the data before passing it to the posterior</span>
<span class="sd">        :param max_iter: maximum number of iterations (i.e. policy updates) that this algorithm runs</span>
<span class="sd">        :param num_real_rollouts: number of real-world rollouts received by sbi, i.e. from every rollout exactly one</span>
<span class="sd">                                  data set is computed</span>
<span class="sd">        :param num_sim_per_round: number of simulations done by sbi per round (i.e. iteration over the same target domain data set)</span>
<span class="sd">        :param num_segments: length of the segments in which the rollouts are split into. For every segment, the initial</span>
<span class="sd">                            state of the simulation is reset, and thus for every set the features of the trajectories</span>
<span class="sd">                            are computed separately. Either specify `num_segments` or `len_segments`.</span>
<span class="sd">        :param len_segments: length of the segments in which the rollouts are split into. For every segment, the initial</span>
<span class="sd">                             state of the simulation is reset, and thus for every set the features of the trajectories</span>
<span class="sd">                             are computed separately. Either specify `num_segments` or `len_segments`.</span>
<span class="sd">        :param num_eval_samples: number of samples for evaluating the posterior in `eval_posterior()`</span>
<span class="sd">        :param posterior_hparam: parameters for creating the posterior of type `MDNPolicy`, e.g. `dict(num_comp=5)` to</span>
<span class="sd">                                 specify the number of mixture components. For more options see `MDNPolicy`.</span>
<span class="sd">        :param subrtn_sbi_training_hparam: hyper-parameters for training the `MDNPolicy` posterior</span>
<span class="sd">        :param subrtn_policy: algorithm which performs the optimization of the behavioral policy (and value-function)</span>
<span class="sd">        :param subrtn_sbi_snapshot_mode: snapshot mode for saving during inference</span>
<span class="sd">        :param subrtn_policy_snapshot_mode: snapshot mode for saving during policy optimization</span>
<span class="sd">        :param thold_succ_subrtn: success threshold on the simulated system&#39;s return for the subroutine, repeat the</span>
<span class="sd">                                  subroutine until the threshold is exceeded or the for a given number of iterations</span>
<span class="sd">        :param num_workers: number of environments for parallel sampling</span>
<span class="sd">        :param logger: logger for every step of the algorithm, if `None` the default logger will be created</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env_sim</span><span class="p">,</span> <span class="n">SimEnv</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env_sim</span><span class="p">,</span> <span class="n">DomainRandWrapper</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">pyrado</span><span class="o">.</span><span class="n">TypeErr</span><span class="p">(</span><span class="n">msg</span><span class="o">=</span><span class="s2">&quot;The given env_sim must be a non-randomized simulation environment!&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">prior</span><span class="o">.</span><span class="n">event_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">dp_mapping</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">pyrado</span><span class="o">.</span><span class="n">ShapeErr</span><span class="p">(</span><span class="n">given</span><span class="o">=</span><span class="n">prior</span><span class="o">.</span><span class="n">event_shape</span><span class="p">,</span> <span class="n">expected_match</span><span class="o">=</span><span class="n">dp_mapping</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">posterior_hparam</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">posterior_hparam</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">posterior_hparam</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">pyrado</span><span class="o">.</span><span class="n">TypeErr</span><span class="p">(</span><span class="n">given</span><span class="o">=</span><span class="n">posterior_hparam</span><span class="p">,</span> <span class="n">expected_type</span><span class="o">=</span><span class="nb">dict</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">subrtn_sbi_training_hparam</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">subrtn_sbi_training_hparam</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">subrtn_sbi_training_hparam</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">pyrado</span><span class="o">.</span><span class="n">TypeErr</span><span class="p">(</span><span class="n">given</span><span class="o">=</span><span class="n">subrtn_sbi_training_hparam</span><span class="p">,</span> <span class="n">expected_type</span><span class="o">=</span><span class="nb">dict</span><span class="p">)</span>

        <span class="c1"># Call Algorithm&#39;s constructor</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BayesSim</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">save_dir</span><span class="o">=</span><span class="n">save_dir</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span> <span class="n">policy</span><span class="o">=</span><span class="n">policy</span><span class="p">,</span> <span class="n">logger</span><span class="o">=</span><span class="n">logger</span><span class="p">)</span>

        <span class="c1"># Set defaults which can be overwritten</span>
        <span class="n">subrtn_sbi_training_hparam</span> <span class="o">=</span> <span class="n">merge_dicts</span><span class="p">([</span><span class="nb">dict</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">),</span> <span class="n">subrtn_sbi_training_hparam</span><span class="p">])</span>
        <span class="n">posterior_hparam</span> <span class="o">=</span> <span class="n">merge_dicts</span><span class="p">([</span><span class="nb">dict</span><span class="p">(</span><span class="n">num_comp</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span> <span class="n">posterior_hparam</span><span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_env_sim</span> <span class="o">=</span> <span class="n">env_sim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_env_sim_trn</span> <span class="o">=</span> <span class="n">DomainRandWrapperBuffer</span><span class="p">(</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">env_sim</span><span class="p">),</span> <span class="n">randomizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">selection</span><span class="o">=</span><span class="s2">&quot;random&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_env_real</span> <span class="o">=</span> <span class="n">env_real</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dp_mapping</span> <span class="o">=</span> <span class="n">dp_mapping</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_embedding</span> <span class="o">=</span> <span class="n">embedding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_sim_per_round</span> <span class="o">=</span> <span class="n">num_sim_per_round</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_real_rollouts</span> <span class="o">=</span> <span class="n">num_real_rollouts</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_segments</span> <span class="o">=</span> <span class="n">num_segments</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">len_segments</span> <span class="o">=</span> <span class="n">len_segments</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_sbi_rounds</span> <span class="o">=</span> <span class="n">num_sbi_rounds</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_eval_samples</span> <span class="o">=</span> <span class="n">num_eval_samples</span> <span class="ow">or</span> <span class="mi">10</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">**</span> <span class="nb">len</span><span class="p">(</span><span class="n">dp_mapping</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">thold_succ_subrtn</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">thold_succ_subrtn</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_subrtn_rep</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of tries to exceed thold_succ_subrtn during training in simulation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span> <span class="o">=</span> <span class="n">num_workers</span>

        <span class="c1"># Create a rollout sampler</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rollout_sampler</span> <span class="o">=</span> <span class="n">SimRolloutSamplerForSBI</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_env_sim</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_policy</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dp_mapping</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_embedding</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_segments</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">len_segments</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Create the posterior</span>
        <span class="n">moe_spec</span> <span class="o">=</span> <span class="n">EnvSpec</span><span class="p">(</span>
            <span class="n">obs_space</span><span class="o">=</span><span class="n">InfBoxSpace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">dim_output</span><span class="p">),</span>
            <span class="n">act_space</span><span class="o">=</span><span class="n">InfBoxSpace</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dp_mapping</span><span class="p">)),</span>
        <span class="p">)</span>
        <span class="n">density_estimator</span> <span class="o">=</span> <span class="n">MDNPolicy</span><span class="p">(</span><span class="n">spec</span><span class="o">=</span><span class="n">moe_spec</span><span class="p">,</span> <span class="o">**</span><span class="n">posterior_hparam</span><span class="p">)</span>

        <span class="c1"># Temporary containers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_curr_data_real</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_curr_domain_param_eval</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># System identification subroutine</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_sbi</span> <span class="o">=</span> <span class="n">SNPEA</span><span class="p">(</span>
            <span class="n">save_dir</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rollout_sampler</span><span class="p">,</span>
            <span class="n">density_estimator</span><span class="p">,</span>
            <span class="n">prior</span><span class="p">,</span>
            <span class="n">num_sim_per_round</span><span class="o">=</span><span class="n">num_sim_per_round</span><span class="p">,</span>
            <span class="n">num_rounds</span><span class="o">=</span><span class="n">num_sbi_rounds</span><span class="p">,</span>
            <span class="o">**</span><span class="n">subrtn_sbi_training_hparam</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_sbi</span><span class="o">.</span><span class="n">save_name</span> <span class="o">=</span> <span class="s2">&quot;subrtn_distr&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_sbi_snapshot_mode</span> <span class="o">=</span> <span class="n">subrtn_sbi_snapshot_mode</span>

        <span class="c1"># Optional policy optimization subroutine</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_policy</span> <span class="o">=</span> <span class="n">subrtn_policy</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_policy</span><span class="p">,</span> <span class="n">Algorithm</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_policy_snapshot_mode</span> <span class="o">=</span> <span class="n">subrtn_policy_snapshot_mode</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_policy</span><span class="o">.</span><span class="n">save_name</span> <span class="o">=</span> <span class="s2">&quot;subrtn_policy&quot;</span>
            <span class="c1"># Check that the behavioral policy is the one that is being updated</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_policy</span><span class="o">.</span><span class="n">policy</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">pyrado</span><span class="o">.</span><span class="n">ValueErr</span><span class="p">(</span>
                    <span class="n">msg</span><span class="o">=</span><span class="s2">&quot;The policy is the policy subroutine is not the same as the one used by &quot;</span>
                    <span class="s2">&quot;the system identification (sbi) subroutine!&quot;</span>
                <span class="p">)</span>

        <span class="c1"># Save initial environments and the prior</span>
        <span class="n">pyrado</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_env_sim</span><span class="p">,</span> <span class="s2">&quot;env_sim.pkl&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_save_dir</span><span class="p">)</span>
        <span class="n">pyrado</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_env_real</span><span class="p">,</span> <span class="s2">&quot;env_real.pkl&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_save_dir</span><span class="p">)</span>
        <span class="n">pyrado</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">embedding</span><span class="p">,</span> <span class="s2">&quot;embedding.pt&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_save_dir</span><span class="p">)</span>
        <span class="n">pyrado</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="s2">&quot;prior.pt&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_save_dir</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">subroutine_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Algorithm</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Get the policy optimization subroutine. &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_policy</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">subroutine_distr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SNPEA</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Get the system identification subroutine coming from the sbi module. &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_sbi</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">embedding</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BayesSimEmbedding</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Get the embedding used to compute the features from the rollouts. &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_embedding</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">posterior</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MDNPolicy</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Get the current (conditional) posterior density estimator. &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_sbi</span><span class="o">.</span><span class="n">posterior</span>

<div class="viewcode-block" id="BayesSim.step"><a class="viewcode-back" href="../../../../algorithms.meta.html#pyrado.algorithms.meta.bayessim.BayesSim.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">snapshot_mode</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">meta_info</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Save snapshot to save the correct iteration count</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_snapshot</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_curr_data_real</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">SBIBase</span><span class="o">.</span><span class="n">collect_data_real</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save_dir</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_env_real</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_policy</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_embedding</span><span class="p">,</span>
            <span class="n">prefix</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;iter_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_curr_iter</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">num_rollouts</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_real_rollouts</span><span class="p">,</span>
            <span class="n">num_segments</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_segments</span><span class="p">,</span>
            <span class="n">len_segments</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">len_segments</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Save the target domain data</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_curr_iter</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Append the first set of data</span>
            <span class="n">pyrado</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_curr_data_real</span><span class="p">,</span> <span class="s2">&quot;data_real.pt&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_save_dir</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Append and save all data</span>
            <span class="n">prev_data</span> <span class="o">=</span> <span class="n">pyrado</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;data_real.pt&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_save_dir</span><span class="p">)</span>
            <span class="n">data_real_hist</span> <span class="o">=</span> <span class="n">to</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">prev_data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_curr_data_real</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">pyrado</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">data_real_hist</span><span class="p">,</span> <span class="s2">&quot;data_real.pt&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_save_dir</span><span class="p">)</span>

        <span class="c1"># Reset the inference subroutine</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_sbi</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

        <span class="c1"># Train the posterior, and save the current iteration&#39;s as well as round&#39;s posterior</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_sbi</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
            <span class="n">snapshot_mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_sbi_snapshot_mode</span><span class="p">,</span>
            <span class="n">meta_info</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">rollouts_real</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_curr_data_real</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;iter_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_curr_iter</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># Override the latest posterior</span>
        <span class="n">pyrado</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_sbi</span><span class="o">.</span><span class="n">posterior</span><span class="p">,</span> <span class="s2">&quot;posterior.pt&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_save_dir</span><span class="p">)</span>

        <span class="c1"># TODO comment this in once SNPE-A is implemented like in the sbi package</span>
        <span class="c1"># Logging (the evaluation can be time-intensive)</span>
        <span class="c1"># posterior = pyrado.load(&quot;posterior.pt&quot;, self._save_dir, meta_info)</span>
        <span class="c1"># self._curr_domain_param_eval, log_probs = SBIBase.eval_posterior(</span>
        <span class="c1">#     posterior,</span>
        <span class="c1">#     self._curr_data_real,</span>
        <span class="c1">#     self.num_eval_samples,</span>
        <span class="c1">#     normalize_posterior=False,</span>
        <span class="c1"># )</span>
        <span class="c1"># self.logger.add_value(  # max likelihood domain parameter set</span>
        <span class="c1">#     &quot;ml domain param&quot;,</span>
        <span class="c1">#     to.mean(self._curr_domain_param_eval[:, to.argmax(log_probs, dim=1), :], dim=[0, 1]),</span>
        <span class="c1">#     2,</span>
        <span class="c1"># )</span>
        <span class="c1"># self.logger.add_value(&quot;std domain param&quot;, to.std(self._curr_domain_param_eval, dim=[0, 1]), 2)</span>
        <span class="c1"># self.logger.add_value(&quot;avg log prob&quot;, to.mean(log_probs), 4)</span>
        <span class="c1"># self.logger.add_value(&quot;num total samples&quot;, self._cnt_samples)  # here the samples are simulations</span>

        <span class="c1"># Policy optimization</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_policy</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Train the behavioral policy using the posterior samples obtained before, repeat if the resulting</span>
            <span class="c1"># policy did not exceed the success threshold</span>
            <span class="n">wrapped_trn_fcn</span> <span class="o">=</span> <span class="n">until_thold_exceeded</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">thold_succ_subrtn</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_subrtn_rep</span><span class="p">)(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_policy_sim</span><span class="p">)</span>
            <span class="n">wrapped_trn_fcn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_curr_domain_param_eval</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">prefix</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;iter_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_curr_iter</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Save snapshot data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">make_snapshot</span><span class="p">(</span><span class="n">snapshot_mode</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">meta_info</span><span class="p">)</span></div>

<div class="viewcode-block" id="BayesSim.train_policy_sim"><a class="viewcode-back" href="../../../../algorithms.meta.html#pyrado.algorithms.meta.bayessim.BayesSim.train_policy_sim">[docs]</a>    <span class="k">def</span> <span class="nf">train_policy_sim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">domain_params</span><span class="p">:</span> <span class="n">to</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train a policy in simulation for given hyper-parameters from the domain randomizer.</span>

<span class="sd">        :param domain_params: domain parameters sampled from the posterior [shape N x D where N is the number of</span>
<span class="sd">                              samples and D is the number of domain parameters]</span>
<span class="sd">        :param prefix: set a prefix to the saved file name by passing it to `meta_info`</span>
<span class="sd">        :return: estimated return of the trained policy in the target domain</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">domain_params</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">domain_params</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dp_mapping</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="n">pyrado</span><span class="o">.</span><span class="n">ShapeErr</span><span class="p">(</span><span class="n">given</span><span class="o">=</span><span class="n">domain_params</span><span class="p">,</span> <span class="n">expected_match</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

        <span class="c1"># Insert the domain parameters into the wrapped environment&#39;s buffer</span>
        <span class="n">NPDR</span><span class="o">.</span><span class="n">fill_domain_param_buffer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_env_sim_trn</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dp_mapping</span><span class="p">,</span> <span class="n">domain_params</span><span class="p">)</span>

        <span class="c1"># Set the initial state spaces of the simulation environment to match the observed initial states</span>
        <span class="n">rollouts_real</span> <span class="o">=</span> <span class="n">pyrado</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;rollouts_real.pkl&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_save_dir</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="n">prefix</span><span class="p">)</span>
        <span class="n">init_states_real</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">ro</span><span class="o">.</span><span class="n">states</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="k">for</span> <span class="n">ro</span> <span class="ow">in</span> <span class="n">rollouts_real</span><span class="p">])</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">init_states_real</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rollouts_real</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_env_sim_trn</span><span class="o">.</span><span class="n">state_space</span><span class="o">.</span><span class="n">flat_dim</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">pyrado</span><span class="o">.</span><span class="n">ShapeErr</span><span class="p">(</span>
                <span class="n">given</span><span class="o">=</span><span class="n">init_states_real</span><span class="p">,</span> <span class="n">expected_match</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rollouts_real</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_env_sim_trn</span><span class="o">.</span><span class="n">state_space</span><span class="o">.</span><span class="n">flat_dim</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_env_sim_trn</span><span class="o">.</span><span class="n">wrapped_env</span><span class="o">.</span><span class="n">init_space</span> <span class="o">=</span> <span class="n">DiscreteSpace</span><span class="p">(</span><span class="n">init_states_real</span><span class="p">)</span>

        <span class="c1"># Reset the subroutine algorithm which includes resetting the exploration</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cnt_samples</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_policy</span><span class="o">.</span><span class="n">sample_count</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_policy</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

        <span class="c1"># Propagate the updated training environment to the SamplerPool&#39;s workers</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_policy</span><span class="p">,</span> <span class="s2">&quot;sampler&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_policy</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">reinit</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_env_sim_trn</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">pyrado</span><span class="o">.</span><span class="n">KeyErr</span><span class="p">(</span><span class="n">keys</span><span class="o">=</span><span class="s2">&quot;sampler&quot;</span><span class="p">,</span> <span class="n">container</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_policy</span><span class="p">)</span>

        <span class="c1"># Train a policy in simulation using the subroutine</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_policy</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">snapshot_mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_policy_snapshot_mode</span><span class="p">,</span> <span class="n">meta_info</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="n">prefix</span><span class="p">))</span>

        <span class="c1"># Return the estimated return of the trained policy in simulation</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_env_sim_trn</span><span class="o">.</span><span class="n">buffer</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_eval_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_env_sim_trn</span><span class="o">.</span><span class="n">ring_idx</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># don&#39;t reset the buffer to eval on the same domains as trained</span>
        <span class="n">avg_ret_sim</span> <span class="o">=</span> <span class="n">SBIBase</span><span class="o">.</span><span class="n">eval_policy</span><span class="p">(</span>
            <span class="kc">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_env_sim_trn</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_policy</span><span class="o">.</span><span class="n">policy</span><span class="p">,</span> <span class="n">prefix</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_eval_samples</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">avg_ret_sim</span><span class="p">)</span></div>

<div class="viewcode-block" id="BayesSim.save_snapshot"><a class="viewcode-back" href="../../../../algorithms.meta.html#pyrado.algorithms.meta.bayessim.BayesSim.save_snapshot">[docs]</a>    <span class="k">def</span> <span class="nf">save_snapshot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">meta_info</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BayesSim</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">save_snapshot</span><span class="p">(</span><span class="n">meta_info</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">meta_info</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># This algorithm instance is not a subroutine of another algorithm</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_policy</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># The policy is not being updated by a policy optimization subroutine</span>
                <span class="n">pyrado</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_policy</span><span class="p">,</span> <span class="s2">&quot;policy.pt&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_dir</span><span class="p">,</span> <span class="n">use_state_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_subrtn_policy</span><span class="o">.</span><span class="n">save_snapshot</span><span class="p">()</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>